{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating biomarker ordering\n",
    "\n",
    ">The sampler for the biomarker ordering can be a bit tricker. The simplest way to do it might be to do a Metropolis-Hastings step where you select two indicies and propose swapping their order. Then you can work out the relative probabilities, evaluate and then accept/reject based on that. It's not the fastest sampler, but it is a lot more straightforward than some ways of doing it.  \n",
    "\n",
    "In the following, we assume we know the actual $\\theta$ and $\\phi$ values. Other than those, we know nothing except for participants' observed biomarker values. And we want to estimate the current order in which different biomarkers are affected by the disease in question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re \n",
    "import altair as alt \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have three columns: biomarker, participant, and measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biomarker</th>\n",
       "      <th>participant</th>\n",
       "      <th>measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.660822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.465804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Biomarker  participant  measurement\n",
       "0         0            0     0.650878\n",
       "1         0            1     0.948132\n",
       "2         0            2     0.833979\n",
       "3         0            3     0.660822\n",
       "4         0            4     0.465804"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/participant_data.csv')\n",
    "data.Biomarker = [re.sub(\"Biomarker \", \"\", text) for text in data.Biomarker.tolist()]\n",
    "data_we_have = data.drop(['k_j', 'S_n', 'affected_or_not'], axis = 1)\n",
    "data_we_have.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biomarker</th>\n",
       "      <th>theta_mean</th>\n",
       "      <th>theta_var</th>\n",
       "      <th>phi_mean</th>\n",
       "      <th>phi_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   biomarker  theta_mean  theta_var  phi_mean  phi_var\n",
       "0          0         1.0        0.3      32.0      6.3\n",
       "1          1         3.0        0.5      31.0      7.4\n",
       "2          2         5.0        0.2      34.0      9.4\n",
       "3          3         6.0        1.3      36.0      4.9\n",
       "4          4         8.0        3.3      38.0      2.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_phi = pd.read_csv('data/means_vars.csv')\n",
    "theta_phi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(theta_phi['biomarker'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_up_pdata(pdata, k_j):\n",
    "    '''Fill up participant data using k_j; basically add two columns: k_j and affected\n",
    "    Note that this function assumes that pdata already has the S_n column\n",
    "    Input:\n",
    "    - pdata: a dataframe of ten biomarker values for a specific participant \n",
    "    - k_j: a scalar\n",
    "    '''\n",
    "    data = pdata.copy()\n",
    "    data['k_j'] = k_j\n",
    "    data['affected'] = data.apply(lambda row: row.k_j >= row.S_n, axis = 1)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_measurement_likelihood(theta_phi, biomarker, affected, measurement):\n",
    "    '''Computes the likelihood of the measurement value of a single biomarker\n",
    "    We know the normal distribution defined by either theta or phi\n",
    "    and we know the measurement. This will give us the probability\n",
    "    of this given measurement value. \n",
    "\n",
    "    Note that because the likelihood tends to be very very small, \n",
    "    we take the natural log of it\n",
    "\n",
    "    input:\n",
    "    - theta_phi: the dataframe containing theta and phi values for each biomarker\n",
    "    - biomarker: an integer between 0 and 9 \n",
    "    - affected: boolean \n",
    "    - measurement: the observed value for a biomarker in a specific participant\n",
    "\n",
    "    output: a scalar\n",
    "    '''\n",
    "    biomarker_params = theta_phi[theta_phi.biomarker == biomarker].reset_index()\n",
    "    mu = biomarker_params['theta_mean'][0] if affected else biomarker_params['phi_mean'][0]\n",
    "    var = biomarker_params['theta_var'][0] if affected else biomarker_params['phi_var'][0]\n",
    "    # sigma = np.sqrt(var)\n",
    "    likelihood = np.exp(-(measurement - mu)**2/(2*var))/np.sqrt(2*np.pi*var)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood(pdata, k_j, theta_phi):\n",
    "    '''This implementes the formula of https://ebm-book2.vercel.app/distributions.html#known-k-j\n",
    "    This function computes the likelihood of seeing this sequence of biomarker values for a specific participant\n",
    "    '''\n",
    "    data = fill_up_pdata(pdata, k_j)\n",
    "    likelihood = 1\n",
    "    for i, row in data.iterrows():\n",
    "        biomarker = int(row['Biomarker'])\n",
    "        measurement = row['measurement']\n",
    "        affected = row['affected']\n",
    "        likelihood *= compute_single_measurement_likelihood(\n",
    "            theta_phi, biomarker, affected, measurement)\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "The above functions can compute the likelihood of a participant's sequence of biomarker data, given that we know the exact ordering and we assume a `k_j`. Next, we will test those functions by selecting a specific participant. We compute the likelihood by trying all possible `k_j` and see whether the one with the highest likelihood is the real `k_j` in the original data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biomarker</th>\n",
       "      <th>participant</th>\n",
       "      <th>measurement</th>\n",
       "      <th>k_j</th>\n",
       "      <th>S_n</th>\n",
       "      <th>affected_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>39.592882</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>not_affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>37.773684</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>not_affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>47.490748</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>not_affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>9.149844</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>40.370867</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>not_affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>31.288837</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>not_affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2.797134</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1.969060</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>35.171580</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>not_affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>35.091867</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>not_affected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Biomarker  participant  measurement  k_j  S_n affected_or_not\n",
       "0         0           15    39.592882    3    4    not_affected\n",
       "1         1           15    37.773684    3    9    not_affected\n",
       "2         2           15    47.490748    3    7    not_affected\n",
       "3         3           15     9.149844    3    3        affected\n",
       "4         4           15    40.370867    3    6    not_affected\n",
       "5         5           15    31.288837    3    5    not_affected\n",
       "6         6           15     2.797134    3    1        affected\n",
       "7         7           15     1.969060    3    2        affected\n",
       "8         8           15    35.171580    3   10    not_affected\n",
       "9         9           15    35.091867    3    8    not_affected"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 15 # we chose this participant\n",
    "pdata = data[data.participant == p].reset_index(drop=True)\n",
    "pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4, 1: 9, 2: 7, 3: 3, 4: 6, 5: 5, 6: 1, 7: 2, 8: 10, 9: 8}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordering of biomarker affected by the disease\n",
    "# biomarker: disease stage\n",
    "# note that the key >= 1\n",
    "real_ordering_dic = dict(zip(np.arange(10), pdata.S_n))\n",
    "real_ordering_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biomarker</th>\n",
       "      <th>participant</th>\n",
       "      <th>measurement</th>\n",
       "      <th>S_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>39.592882</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>37.773684</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>47.490748</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>9.149844</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>40.370867</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>31.288837</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2.797134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1.969060</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>35.171580</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>35.091867</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Biomarker  participant  measurement  S_n\n",
       "0         0           15    39.592882    4\n",
       "1         1           15    37.773684    9\n",
       "2         2           15    47.490748    7\n",
       "3         3           15     9.149844    3\n",
       "4         4           15    40.370867    6\n",
       "5         5           15    31.288837    5\n",
       "6         6           15     2.797134    1\n",
       "7         7           15     1.969060    2\n",
       "8         8           15    35.171580   10\n",
       "9         9           15    35.091867    8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the participant data without k_j, S_n, and affected or not\n",
    "pdata = data_we_have[data_we_have.participant == p].reset_index(drop=True)\n",
    "# obtain real ordering:\n",
    "pdata['S_n'] = pdata.apply(lambda row: real_ordering_dic[int(row['Biomarker'])], axis = 1)\n",
    "pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.924324e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.086838e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.993061e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.404432e-103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index     likelihood\n",
       "3       3   7.924324e-20\n",
       "2       2   2.086838e-50\n",
       "1       1   4.993061e-78\n",
       "0       0  3.404432e-103\n",
       "4       4   0.000000e+00\n",
       "5       5   0.000000e+00\n",
       "6       6   0.000000e+00\n",
       "7       7   0.000000e+00\n",
       "8       8   0.000000e+00\n",
       "9       9   0.000000e+00\n",
       "10     10   0.000000e+00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_biomarkers = len(pdata.Biomarker.unique())\n",
    "# calculate likelihood for all possible k_j\n",
    "likelihood_list = [\n",
    "    compute_likelihood(pdata=pdata, k_j=x, theta_phi=theta_phi) for x in range(num_biomarkers+1)]\n",
    "kjs = np.arange(11)\n",
    "dic = dict(zip(kjs, likelihood_list))\n",
    "df = pd.DataFrame.from_dict(dic, orient='index', columns=['likelihood']).reset_index()\n",
    "df.sort_values('likelihood', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- From the above result, we can see that the most likelihood `k_j` is 8, which is in fact the real `k_j` in the participant data.  -->\n",
    "\n",
    "## Metropolis-Hastings Algorithm Implementation\n",
    "\n",
    "Next, we will implement the metropolis-hastings algorithm using the above functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_all_likelihood(pdata, num_biomarkers, theta_phi):\n",
    "    '''This is to compute https://ebm-book2.vercel.app/distributions.html#unknown-k-j\n",
    "    '''\n",
    "    return np.mean([compute_likelihood(pdata=pdata, k_j=x, theta_phi=theta_phi) for x in range(num_biomarkers+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_likelihood_based_on_ordering(ordering, data, num_participants, num_biomarkers, theta_phi):\n",
    "    \"\"\"Compute the likelihood of all participants having their data\n",
    "    Inputs:\n",
    "        - ordering: an array of ordering for biomarker 0-9\n",
    "        - data: data_we_have\n",
    "        - num_participants\n",
    "        - num_biomarkers \n",
    "    Outputs:\n",
    "        - likelihood\n",
    "    \"\"\"\n",
    "    # biomarker - order dict\n",
    "    ordering_dic = dict(zip(np.arange(num_biomarkers), ordering))\n",
    "    # fill up S_n column using the ordering dict\n",
    "    # copy first in order not to change data_we_have\n",
    "    filled_data = data.copy()\n",
    "    filled_data['S_n'] = filled_data.apply(lambda row: ordering_dic[int(row['Biomarker'])], axis = 1)\n",
    "    likelihood = 0 \n",
    "    for p in range(num_participants):\n",
    "        pdata = filled_data[filled_data.participant == p].reset_index(drop=True)\n",
    "        average_likelihood = average_all_likelihood(pdata, num_biomarkers, theta_phi)\n",
    "        # print(average_likelihood)\n",
    "        if average_likelihood == 0:\n",
    "            # this is to avoid np.log(0)\n",
    "            log_likelihood = np.log(average_likelihood + 1e-20)\n",
    "        else:\n",
    "            log_likelihood = np.log(average_likelihood)\n",
    "            # print(log_likelihood)\n",
    "        likelihood += log_likelihood\n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(data, iterations, theta_phi):\n",
    "    '''Implement the metropolis-hastings algorithm\n",
    "    Inputs: \n",
    "        - data: data_we_have\n",
    "        - iterations: number of iterations\n",
    "\n",
    "    Outputs:\n",
    "        - best_order: a numpy array\n",
    "        - best_likelihood: a scalar \n",
    "    '''\n",
    "    num_participants = len(data.participant.unique())\n",
    "    num_biomarkers = len(data.Biomarker.unique())\n",
    "\n",
    "    # initialize an ordering and likelihood\n",
    "    # note that it should be a random permutation of numbers 1-10\n",
    "    best_order = np.random.permutation(np.arange(1, 11))\n",
    "    best_likelihood = -np.inf \n",
    "    # best_order = np.array(list(real_ordering_dic.values()))\n",
    "    # best_likelihood = compute_likelihood_based_on_ordering(\n",
    "    #     best_order, data, num_participants, num_biomarkers, theta_phi\n",
    "    # )\n",
    "    for _ in range(iterations):\n",
    "        new_order = best_order.copy()\n",
    "        # randomly select two indices\n",
    "        a, b = np.random.choice(num_biomarkers, 2, replace=False)\n",
    "        # swaping the order\n",
    "        new_order[a], new_order[b] = new_order[b], new_order[a]\n",
    "        likelihood = compute_likelihood_based_on_ordering(new_order, data, num_participants, num_biomarkers, theta_phi)\n",
    "        if likelihood > best_likelihood:\n",
    "            best_likelihood = likelihood \n",
    "            best_order = new_order\n",
    "        else: \n",
    "            ratio = likelihood/best_likelihood\n",
    "            # I am not sure about the following: \n",
    "            # log_diff = best_likelihood - likelihood\n",
    "            random_number = np.random.rand()\n",
    "            if random_number < ratio:\n",
    "                best_likelihood = likelihood\n",
    "                best_order = new_order\n",
    "        print(f\"iteration {_ + 1} done\")\n",
    "    return best_order, best_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 4 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 6 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 7 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 8 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 9 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10 done\n"
     ]
    }
   ],
   "source": [
    "best_order, best_likelihood = metropolis_hastings(data_we_have, 10, theta_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4,  1,  9,  6, 10,  2,  7,  8,  5,  3]),\n",
       " array([ 4,  9,  7,  3,  6,  5,  1,  2, 10,  8]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_order, np.array(list(real_ordering_dic.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unknown theta and phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found it challenging to infer the ordering of biomarkers affected by the disease without knowing theta and phi. This is because we do not need to now participants' real disease stage in the formula of https://ebm-book2.vercel.app/distributions.html#unknown-k-j, however, without knowing all participants' disease stages, we are not able to estimate theta and phi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biomarker</th>\n",
       "      <th>participant</th>\n",
       "      <th>measurement</th>\n",
       "      <th>k_j</th>\n",
       "      <th>S_n</th>\n",
       "      <th>affected_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650878</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948132</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833979</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.660822</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.465804</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>affected</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Biomarker  participant  measurement  k_j  S_n affected_or_not\n",
       "0         0            0     0.650878    8    4        affected\n",
       "1         0            1     0.948132    5    4        affected\n",
       "2         0            2     0.833979    9    4        affected\n",
       "3         0            3     0.660822    7    4        affected\n",
       "4         0            4     0.465804    9    4        affected"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  5,  9,  7,  9,  1,  0,  5, 10,  7,  6,  5,  2, 10,  8,  3,  5,\n",
       "        7, 10, 10,  9,  0,  6,  0,  4,  9,  6,  8,  1,  6,  5,  5,  1,  1,\n",
       "       10,  5,  8,  5,  5, 10, 10,  0,  2,  9,  6,  0,  9,  8, 10,  7, 10,\n",
       "        0,  5,  1,  5,  5,  0,  0, 10,  6,  8,  6,  4,  3, 10,  4,  1,  1,\n",
       "        4,  1,  4,  0,  9,  8,  4,  3,  3,  8,  1, 10, 10,  3,  4,  4,  3,\n",
       "        1,  5,  1, 10,  6,  3, 10,  0,  1,  7,  4,  3,  2,  4,  1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_stage_dict = dict(zip(data.participant, data.k_j))\n",
    "actual_stages = np.array(list(actual_stage_dict.values()))\n",
    "actual_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biomarker</th>\n",
       "      <th>participant</th>\n",
       "      <th>measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.650878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.948132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.833979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.660822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.465804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Biomarker  participant  measurement\n",
       "0         0            0     0.650878\n",
       "1         0            1     0.948132\n",
       "2         0            2     0.833979\n",
       "3         0            3     0.660822\n",
       "4         0            4     0.465804"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_we_have.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_kj_and_affected(data_we_have, participant_stages, num_participants):\n",
    "    '''This is to fill up data_we_have. \n",
    "    Basically, add two columns: k_j, and affected, based on the initial or updated participant_stages\n",
    "    \n",
    "    Inputs:\n",
    "        - data_we_have\n",
    "        - participant_stages: np array \n",
    "        - participants: 0-199\n",
    "    '''\n",
    "    participant_stage_dic = dict(zip(np.arange(0,num_participants), participant_stages))\n",
    "    data_we_have['k_j'] = data_we_have.apply(lambda row: participant_stage_dic[row.participant], axis = 1)\n",
    "    data_we_have['affected'] = data_we_have.apply(lambda row: row.k_j >= row.S_n, axis = 1)\n",
    "    return data_we_have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_params_exact(m0, n0, s0_sq, v0, data):\n",
    "    '''This is to estimate means and vars based on conjugate priors\n",
    "    Inputs:\n",
    "        - data: a vector of measurements for a specific biomarker in a specific group (affected or not)\n",
    "        - m0: prior estimate of $\\mu$.\n",
    "        - n0: how strongly is the prior belief in $m_0$ is held.\n",
    "        - s0_sq: prior estimate of $\\sigma^2$.\n",
    "        - v0: prior degress of freedome, influencing the certainty of $s_0^2$.\n",
    "    \n",
    "    Outputs:\n",
    "        - mu estiate, var estimate\n",
    "    '''\n",
    "    # Data summary\n",
    "    sample_mean = np.mean(data)\n",
    "    sample_size = len(data)\n",
    "    sample_var = np.var(data, ddof=1)  # ddof=1 for unbiased estimator\n",
    "\n",
    "    # Update hyperparameters for the Normal-Inverse Gamma posterior\n",
    "    updated_m0 = (n0 * m0 + sample_size * sample_mean) / (n0 + sample_size)\n",
    "    updated_n0 = n0 + sample_size\n",
    "    updated_v0 = v0 + sample_size \n",
    "    updated_s0_sq = (1 / updated_v0) * ((sample_size - 1) * sample_var + v0 * s0_sq + \n",
    "                    (n0 * sample_size / updated_n0) * (sample_mean - m0)**2)\n",
    "    updated_alpha = updated_v0/2\n",
    "    updated_beta = updated_v0*updated_s0_sq/2\n",
    "\n",
    "    # Posterior estimates\n",
    "    mu_posterior_mean = updated_m0\n",
    "    sigma_squared_posterior_mean = updated_beta/updated_alpha\n",
    "\n",
    "    return mu_posterior_mean, sigma_squared_posterior_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimated_theta_phi(num_biomarkers, data_we_have):\n",
    "    '''To get estimated parameters, returns a Pandas DataFrame\n",
    "    Input:\n",
    "    - num_biomarkers: 10\n",
    "    - data_we_have: full data filled up by S_n, k_j and affected\n",
    "\n",
    "    Output: \n",
    "    - estimate_means_vars_df, just like means_vars_df, containing the estimated mean and var for \n",
    "      distribution of biomarker values when the biomarker is affected and not affected\n",
    "    '''\n",
    "    # empty list of dictionaries to store the estimations\n",
    "    means_vars_estimate_dict_list = []\n",
    "    # 0 - 9\n",
    "    for biomarker in range(num_biomarkers): \n",
    "        dic = {'biomarker': biomarker}  # Initialize dictionary outside the inner loop\n",
    "        for affected in [True, False]:\n",
    "            data_full = data_we_have[(data_we_have.Biomarker == str(biomarker)) & (\n",
    "            data_we_have.affected == affected)]\n",
    "            data = np.array(data_full.measurement)\n",
    "            if len(data) == 0:\n",
    "                print(biomarker)\n",
    "                print(data_full)\n",
    "            mu_estimate, var_estimate = estimate_params_exact(\n",
    "                m0 = 0, n0 = 1, s0_sq = 1, v0 = 1, data=data)\n",
    "            if affected:\n",
    "                dic['theta_mean'] = mu_estimate\n",
    "                dic['theta_var'] = var_estimate\n",
    "            else:\n",
    "                dic['phi_mean'] = mu_estimate\n",
    "                dic['phi_var'] = var_estimate\n",
    "        means_vars_estimate_dict_list.append(dic)\n",
    "    estimate_theta_phi = pd.DataFrame(means_vars_estimate_dict_list)\n",
    "    return estimate_theta_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_unknown_theta_phi(data_we_have, iterations):\n",
    "    num_participants = len(data_we_have.participant.unique())\n",
    "    num_biomarkers = len(data_we_have.Biomarker.unique())\n",
    "\n",
    "    # initialize an ordering and likelihood\n",
    "    # note that it should be a random permutation of numbers 1-10\n",
    "    best_order = np.random.permutation(np.arange(1, 11))\n",
    "    best_likelihood = -np.inf \n",
    "\n",
    "    for _ in range(iterations):\n",
    "        new_order = best_order.copy()\n",
    "        # randomly select two indices\n",
    "        a, b = np.random.choice(num_biomarkers, 2, replace=False)\n",
    "        # swaping the order\n",
    "        new_order[a], new_order[b] = new_order[b], new_order[a]\n",
    "\n",
    "        # likelihood of seeing all participants' data \n",
    "        # biomarker - order dict\n",
    "        ordering_dic = dict(zip(np.arange(num_biomarkers), new_order))\n",
    "        # fill up S_n column using the ordering dict\n",
    "        # copy first in order not to change data_we_have\n",
    "        data = data_we_have.copy()\n",
    "        # now data_we_have has S_n column\n",
    "        data['S_n'] = data.apply(lambda row: ordering_dic[int(row['Biomarker'])], axis = 1)\n",
    "\n",
    "        # initialize participant_stages \n",
    "        # note that high should be num_stages + 1; otherwise, no participants will be in the stage of 10\n",
    "        participant_stages = np.random.randint(low = 0, high = num_biomarkers+1, size = num_participants)\n",
    "\n",
    "        # add kj and affected\n",
    "        data = add_kj_and_affected(data, participant_stages, num_participants)\n",
    "        # print(data.head())\n",
    "\n",
    "        # get estimated_theta_phi\n",
    "        estimated_theta_phi = get_estimated_theta_phi(num_biomarkers, data_we_have=data)\n",
    "\n",
    "        all_participant_likelihood = 0 \n",
    "        for p in range(num_participants):\n",
    "            pdata = data[data.participant == p].reset_index(drop=True)\n",
    "            # initiaze stage_likelihood\n",
    "            stage_likelihood = np.zeros(num_biomarkers + 1)\n",
    "            for k_j in range(num_biomarkers +1):\n",
    "                # even though data above has everything, it is filled up by random stages\n",
    "                # we don't like it and want to know the true k_j\n",
    "                pdata_with_this_kj = fill_up_pdata(pdata=pdata, k_j=k_j)\n",
    "                # likelihood for this participant to have this sequence of biomarker values\n",
    "                participant_likelihood = 1\n",
    "                for i, row in pdata_with_this_kj.iterrows():\n",
    "                    biomarker = int(row['Biomarker'])\n",
    "                    measurement = row['measurement']\n",
    "                    affected = row['affected']\n",
    "                    participant_likelihood *= compute_single_measurement_likelihood(\n",
    "                        estimated_theta_phi, biomarker, affected, measurement)\n",
    "                stage_likelihood[k_j] = participant_likelihood\n",
    "            likelihood_sum = np.sum(stage_likelihood)\n",
    "            normalized_stage_likelihood = [l/likelihood_sum for l in stage_likelihood]\n",
    "            sampled_stage = np.random.choice(np.arange(num_biomarkers + 1), p = normalized_stage_likelihood)\n",
    "            participant_stages[p] = sampled_stage     \n",
    "\n",
    "            # formula here: https://ebm-book2.vercel.app/distributions.html#unknown-k-j\n",
    "            average_likelihood = np.mean(stage_likelihood)\n",
    "            if average_likelihood == 0:\n",
    "                print(f'averge likelihood is zero')\n",
    "                log_average_likelihood = np.log(average_likelihood + 1e-20)\n",
    "            else:\n",
    "                log_average_likelihood = np.log(average_likelihood)\n",
    "            all_participant_likelihood += log_average_likelihood\n",
    "\n",
    "        # if all_participant_likelihood == 0:\n",
    "        #     print(\"all_participant_likelihood is zero\")\n",
    "            \n",
    "        # if np.any(participant_stages == 0):\n",
    "        #     print(\"0 is in participant stages\")\n",
    "        # else:\n",
    "        #     print(\"0 is not in participant stages\")\n",
    "        if  all_participant_likelihood > best_likelihood:\n",
    "            best_likelihood = all_participant_likelihood \n",
    "            best_order = new_order\n",
    "        else: \n",
    "            ratio = all_participant_likelihood/best_likelihood\n",
    "            random_number = np.random.rand()\n",
    "            if random_number < ratio:\n",
    "                best_likelihood = all_participant_likelihood\n",
    "                best_order = new_order\n",
    "        print(f\"iteration {_ + 1} done\")\n",
    "    return best_order, best_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 4 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 6 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 7 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 8 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 9 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10 done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 11 done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_order, best_likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mmetropolis_hastings_unknown_theta_phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_we_have\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 52\u001b[0m, in \u001b[0;36mmetropolis_hastings_unknown_theta_phi\u001b[0;34m(data_we_have, iterations)\u001b[0m\n\u001b[1;32m     50\u001b[0m         measurement \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeasurement\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     51\u001b[0m         affected \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maffected\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 52\u001b[0m         participant_likelihood \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcompute_single_measurement_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimated_theta_phi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbiomarker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasurement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     stage_likelihood[k_j] \u001b[38;5;241m=\u001b[39m participant_likelihood\n\u001b[1;32m     55\u001b[0m likelihood_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(stage_likelihood)\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mcompute_single_measurement_likelihood\u001b[0;34m(theta_phi, biomarker, affected, measurement)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Computes the likelihood of the measurement value of a single biomarker\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mWe know the normal distribution defined by either theta or phi\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mand we know the measurement. This will give us the probability\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03moutput: a scalar\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     18\u001b[0m biomarker_params \u001b[38;5;241m=\u001b[39m theta_phi[theta_phi\u001b[38;5;241m.\u001b[39mbiomarker \u001b[38;5;241m==\u001b[39m biomarker]\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m---> 19\u001b[0m mu \u001b[38;5;241m=\u001b[39m \u001b[43mbiomarker_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtheta_mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m affected \u001b[38;5;28;01melse\u001b[39;00m biomarker_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphi_mean\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m var \u001b[38;5;241m=\u001b[39m biomarker_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta_var\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m affected \u001b[38;5;28;01melse\u001b[39;00m biomarker_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphi_var\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# sigma = np.sqrt(var)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bayes/lib/python3.8/site-packages/pandas/core/frame.py:3770\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3766\u001b[0m is_mi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex)\n\u001b[1;32m   3767\u001b[0m \u001b[38;5;66;03m# GH#45316 Return view if key is not duplicated\u001b[39;00m\n\u001b[1;32m   3768\u001b[0m \u001b[38;5;66;03m# Only use drop_duplicates with duplicates for performance\u001b[39;00m\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m-> 3770\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_unique\u001b[49m\n\u001b[1;32m   3771\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3772\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop_duplicates(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3773\u001b[0m ):\n\u001b[1;32m   3774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(key)\n\u001b[1;32m   3776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m~/anaconda3/envs/bayes/lib/python3.8/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/bayes/lib/python3.8/site-packages/pandas/core/indexes/base.py:2386\u001b[0m, in \u001b[0;36mIndex.is_unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2381\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_unique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   2383\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2384\u001b[0m \u001b[38;5;124;03m    Return if the index has unique values.\u001b[39;00m\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241m.\u001b[39mis_unique\n",
      "File \u001b[0;32m~/anaconda3/envs/bayes/lib/python3.8/site-packages/pandas/_libs/properties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/bayes/lib/python3.8/site-packages/pandas/core/indexes/base.py:886\u001b[0m, in \u001b[0;36mIndex._engine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_engine\u001b[39m(\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    884\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m libindex\u001b[38;5;241m.\u001b[39mIndexEngine \u001b[38;5;241m|\u001b[39m libindex\u001b[38;5;241m.\u001b[39mExtensionEngine:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;66;03m# For base class (object dtype) we get ObjectEngine\u001b[39;00m\n\u001b[0;32m--> 886\u001b[0m     target_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_engine_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(target_values, ExtensionArray)\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine_type \u001b[38;5;129;01mis\u001b[39;00m libindex\u001b[38;5;241m.\u001b[39mObjectEngine\n\u001b[1;32m    890\u001b[0m     ):\n\u001b[1;32m    891\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m libindex\u001b[38;5;241m.\u001b[39mExtensionEngine(target_values)\n",
      "File \u001b[0;32m~/anaconda3/envs/bayes/lib/python3.8/site-packages/pandas/core/indexes/base.py:5125\u001b[0m, in \u001b[0;36mIndex._get_engine_target\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(vals, StringArray):\n\u001b[1;32m   5123\u001b[0m     \u001b[38;5;66;03m# GH#45652 much more performant than ExtensionEngine\u001b[39;00m\n\u001b[1;32m   5124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vals\u001b[38;5;241m.\u001b[39m_ndarray\n\u001b[0;32m-> 5125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Index \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m, ExtensionArray):\n\u001b[1;32m   5126\u001b[0m     \u001b[38;5;66;03m# TODO(ExtensionIndex): remove special-case, just use self._values\u001b[39;00m\n\u001b[1;32m   5127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m   5128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vals\n",
      "File \u001b[0;32m~/anaconda3/envs/bayes/lib/python3.8/site-packages/pandas/core/indexes/base.py:5114\u001b[0m, in \u001b[0;36mIndex._values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5090\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   5091\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_values\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ExtensionArray \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   5092\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5093\u001b[0m \u001b[38;5;124;03m    The best array representation.\u001b[39;00m\n\u001b[1;32m   5094\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5112\u001b[0m \u001b[38;5;124;03m    values : Values\u001b[39;00m\n\u001b[1;32m   5113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_order, best_likelihood = metropolis_hastings_unknown_theta_phi(data_we_have, iterations = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  7,  9,  5,  1,  3,  4, 10,  6,  8]),\n",
       " array([ 7,  5,  3,  9,  1,  2,  6, 10,  4,  8]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_order, np.array(list(real_ordering_dic.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}